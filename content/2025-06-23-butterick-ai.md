+++
title = "Domination: a contrarian view of AI risk"
date = 2024-06-23
extra.symbol = "precision_manufacturing"
extra.link = "https://matthewbutterick.com/chron/domination.html"
+++

> There are many cata­strophe-class AI events that don’t require AI to kill us
> or other­wise impair our phys­ical health. For instance, I expect that most
> humans would also consider it cata­strophic if, say, AI griev­ously impaired
> our polit­ical system, our economic system, our popular culture, our
> intel­lec­tual devel­op­ment, or our emotional health. Those are all on the
> table too. And much more likely than literal anni­hi­la­tion.
